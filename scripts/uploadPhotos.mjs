import { mkdir, readdir, readFile, copyFile, writeFile, stat } from 'fs/promises';
import path from 'path';
import sharp from 'sharp';

const ROOT = process.cwd();
const PHOTOS_DIR = path.join(ROOT, 'public', 'photos');
const OUTPUT_DIR = process.env.UPLOAD_OUTPUT_DIR
  ? path.resolve(ROOT, process.env.UPLOAD_OUTPUT_DIR)
  : PHOTOS_DIR;

const SUPPORTED_IMAGE_EXTS = ['.png', '.jpg', '.jpeg', '.webp', '.PNG', '.JPG', '.JPEG', '.WEBP'];
const COMPRESS_QUALITY = Number.parseInt(process.env.COMPRESS_QUALITY || '80', 10);
const COMPRESS_MAX_SIZE = Number.parseInt(process.env.COMPRESS_MAX_SIZE || '1920', 10);
const SKIP_COMPRESSION = process.env.SKIP_COMPRESSION === 'true';
const usedDays = new Set();
const REQUIRED_TEXT_FIELDS = ['title', 'cache_key'];
// Body is optional - it can be empty and will be generated by generate:bodies script
const OPTIONAL_TEXT_FIELDS = ['body'];
const FIELD_ALIASES = {
  title: ['title', 'Title'],
  subtitle: ['subtitle', 'Subtitle', 'summary', 'Summary'],
  body: ['body', 'Body', 'prompt', 'Prompt'],
  cache_key: ['cache_key', 'cacheKey', 'CacheKey'],
  day: ['day', 'Day', 'date', 'Date'],
};
const FALLBACK_SUBTITLE =
  (process.env.UPLOAD_SUBTITLE && process.env.UPLOAD_SUBTITLE.trim()) ||
  'Daddy Loves You!';

const findRawField = (source, field) => {
  const aliases = FIELD_ALIASES[field] ?? [field];
  for (const alias of aliases) {
    if (Object.prototype.hasOwnProperty.call(source, alias)) {
      return source[alias];
    }
  }
  return undefined;
};

const coerceTextField = (source, field) => {
  const rawValue = findRawField(source, field);
  if (rawValue === undefined || rawValue === null) {
    return undefined;
  }

  const value = String(rawValue).trim();
  return value.length === 0 ? undefined : value;
};

function normalizeMetadata(baseName, raw) {
  const metadata = { ...raw };
  const missingFields = [];

  REQUIRED_TEXT_FIELDS.forEach((field) => {
    const value = coerceTextField(raw, field);
    if (!value) {
      missingFields.push(field);
      return;
    }
    metadata[field] = value;
  });

  // Handle optional fields (can be empty)
  OPTIONAL_TEXT_FIELDS.forEach((field) => {
    const value = coerceTextField(raw, field);
    // Allow empty string for optional fields (will be generated later)
    metadata[field] = value ?? '';
  });

  const subtitleValue = coerceTextField(raw, 'subtitle');
  metadata.subtitle = subtitleValue ?? FALLBACK_SUBTITLE;

  const rawDay = findRawField(raw, 'day');
  if (rawDay === undefined || rawDay === null || rawDay === '') {
    missingFields.push('day');
  } else {
    const dayNumber = typeof rawDay === 'number' ? rawDay : Number.parseInt(String(rawDay), 10);
    if (!Number.isFinite(dayNumber) || !Number.isInteger(dayNumber) || dayNumber < 1 || dayNumber > 25) {
      throw new Error(`metadata field "day" must be an integer between 1 and 25 (received ${rawDay})`);
    }
    metadata.day = dayNumber;
  }

  if (missingFields.length > 0) {
    throw new Error(`metadata missing required field(s): ${missingFields.join(', ')}`);
  }

  return metadata;
}

async function ensureMetadata(baseName) {
  // Try regular JSON first, then fall back to _compressed.json
  const jsonPath = path.join(PHOTOS_DIR, `${baseName}.json`);
  const compressedJsonPath = path.join(PHOTOS_DIR, `${baseName}_compressed.json`);
  
  let jsonPathToUse = jsonPath;
  
  // Check if regular JSON exists, otherwise try compressed version
  try {
    await stat(jsonPath);
  } catch {
    // Regular JSON doesn't exist, try compressed version
    try {
      await stat(compressedJsonPath);
      jsonPathToUse = compressedJsonPath;
    } catch {
      throw new Error(`metadata file missing or invalid JSON (${jsonPath})`);
    }
  }
  
  try {
    const raw = await readFile(jsonPathToUse, 'utf8');
    const parsed = JSON.parse(raw);
    return normalizeMetadata(baseName, parsed);
  } catch (error) {
    throw new Error(`metadata file missing or invalid JSON (${jsonPathToUse})`);
  }
}

async function compressImage(inputPath, outputPath) {
  try {
    const image = sharp(inputPath);
    const metadata = await image.metadata();
    const ext = path.extname(inputPath).toLowerCase();

    let pipeline = image;

    // Resize if needed
    if (metadata.width > COMPRESS_MAX_SIZE || metadata.height > COMPRESS_MAX_SIZE) {
      pipeline = pipeline.resize(COMPRESS_MAX_SIZE, COMPRESS_MAX_SIZE, {
        fit: 'inside',
        withoutEnlargement: true,
      });
    }

    // Apply compression based on format
    if (ext === '.jpg' || ext === '.jpeg') {
      await pipeline
        .jpeg({ quality: COMPRESS_QUALITY, mozjpeg: true })
        .toFile(outputPath);
    } else if (ext === '.png') {
      await pipeline
        .png({ quality: COMPRESS_QUALITY, compressionLevel: 9, adaptiveFiltering: true })
        .toFile(outputPath);
    } else if (ext === '.webp') {
      await pipeline
        .webp({ quality: COMPRESS_QUALITY })
        .toFile(outputPath);
    } else {
      // For unknown formats, just copy
      await copyFile(inputPath, outputPath);
    }
  } catch (error) {
    throw new Error(`compression failed: ${error.message}`);
  }
}

async function writeLocalBundle(imageFile, metadata) {
  await mkdir(OUTPUT_DIR, { recursive: true });
  const parsed = path.parse(imageFile);
  const baseName = parsed.name;
  const ext = parsed.ext;

  // Write original files
  const destImage = path.join(OUTPUT_DIR, `${baseName}${ext}`);
  const destMetadata = path.join(OUTPUT_DIR, `${baseName}.json`);
  const sourceImage = path.resolve(imageFile);
  const targetImage = path.resolve(destImage);
  
  if (sourceImage !== targetImage) {
    await copyFile(sourceImage, targetImage);
  }
  await writeFile(destMetadata, JSON.stringify(metadata, null, 2));

  // Create compressed versions if not skipping
  if (!SKIP_COMPRESSION) {
    try {
      const compressedImagePath = path.join(OUTPUT_DIR, `${baseName}_compressed${ext}`);
      const compressedMetadataPath = path.join(OUTPUT_DIR, `${baseName}_compressed.json`);

      await compressImage(sourceImage, compressedImagePath);
      await writeFile(compressedMetadataPath, JSON.stringify(metadata, null, 2));

      // Get file sizes for logging
      const originalStats = await stat(sourceImage);
      const compressedStats = await stat(compressedImagePath);
      const reduction = ((1 - compressedStats.size / originalStats.size) * 100).toFixed(1);
      console.log(
        `[upload:photos] Compressed ${baseName}: ${(originalStats.size / 1024 / 1024).toFixed(2)}MB â†’ ${(compressedStats.size / 1024 / 1024).toFixed(2)}MB (${reduction}% reduction)`
      );
    } catch (error) {
      console.warn(`[upload:photos] Warning: Failed to compress ${baseName}: ${error.message}`);
    }
  }
}

async function run() {
  const entries = await readdir(PHOTOS_DIR, { withFileTypes: true });
  const images = entries.filter((entry) => {
    if (!entry.isFile()) return false;
    const ext = path.extname(entry.name);
    return SUPPORTED_IMAGE_EXTS.includes(ext);
  });

  let processed = 0;
  let skipped = 0;
  const errors = [];

  for (const img of images) {
    const baseName = path.parse(img.name).name;
    // Skip already compressed files
    if (baseName.endsWith('_compressed')) {
      continue;
    }
    const imagePath = path.join(PHOTOS_DIR, img.name);

    try {
      const metadata = await ensureMetadata(baseName);

      if (usedDays.has(metadata.day)) {
        throw new Error(`duplicate day value ${metadata.day}`);
      }

      usedDays.add(metadata.day);
      await writeLocalBundle(imagePath, metadata);
      processed++;
      console.log(`[upload:photos] Prepared ${img.name} (day ${metadata.day})`);
    } catch (error) {
      skipped++;
      const errorMsg = `Skipping ${img.name}: ${error.message}`;
      console.error(`[upload:photos] ${errorMsg}`);
      errors.push(errorMsg);
    }
  }

  console.log(`\n[upload:photos] Summary: ${processed} processed, ${skipped} skipped`);
  if (errors.length > 0) {
    console.log(`[upload:photos] Errors encountered: ${errors.length}`);
  }
}

run().catch((error) => {
  console.error('[upload:photos] Fatal error', error);
  process.exit(1);
});
